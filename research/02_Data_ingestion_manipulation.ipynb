{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder, RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataIngestionManipulationConfig:\n",
    "    root_dir: Path\n",
    "    local_data_file: Path\n",
    "    source_URL: str\n",
    "    save_training_file: Path\n",
    "    param_target_col: str\n",
    "    param_random_state: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Mushroom_Classification.utils.common import create_directories, read_yaml, save_data, read_file\n",
    "from Mushroom_Classification.constants import *\n",
    "from Mushroom_Classification import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self,\n",
    "                 config_filepath = CONFIG_FILE_PATH,\n",
    "                 params_filepath = PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root]) #the artifacts_root is the key of the dictionary created\n",
    "                                                # in the yaml file and we can read this key like that instead of\n",
    "                                                # [\"artifacts_root\"] because we used the ConfigBox in the common.py file\n",
    "\n",
    "\n",
    "    def get_data_ingestion_config(self) -> DataIngestionManipulationConfig:\n",
    "        config = self.config.data_ingestion_manipulation #data ingestion is the other key value of the dictionary in the config.yaml file\n",
    "\n",
    "        create_directories([config.root_dir,config.save_training_file])\n",
    "\n",
    "        data_ingestion_manipulation_config = DataIngestionManipulationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            local_data_file = config.local_data_file,\n",
    "            source_URL = config.source_URL,\n",
    "            save_training_file= config.save_training_file,\n",
    "            param_target_col=self.params.TARGET,\n",
    "            param_random_state=self.params.RANDOM_STATE\n",
    "        )                                     \n",
    "\n",
    "        return data_ingestion_manipulation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request as request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataIngestionManipulation:\n",
    "    def __init__(self, config: DataIngestionManipulationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def download_file(self):\n",
    "        \"\"\"\n",
    "        file_path: str\n",
    "        Download, if it doesn't already exists, the csv file with data, don't need a return, just to save the Data\n",
    "        \"\"\"\n",
    "        file = \"mushrooms.csv\" \n",
    "        new_path = os.path.join(self.config.local_data_file,file)\n",
    "        if not os.path.exists(new_path):\n",
    "            filename, headers = request.urlretrieve(\n",
    "                url = self.config.source_URL,\n",
    "                filename= new_path\n",
    "            )\n",
    "\n",
    "            logger.info(f\"{file} is downloading!\")\n",
    "        else:\n",
    "            logger.info(f\"File already downloaded\")\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    \n",
    "\n",
    "    def preprocess_file(self):\n",
    "        \"\"\"\n",
    "        Preprocess the data and save it into a training and testing files\n",
    "        \"\"\"\n",
    "        raw_data = read_file(Path(self.config.local_data_file), \"mushrooms.csv\")\n",
    "        numerical_cols = raw_data.select_dtypes(include='number').columns\n",
    "        categorical_cols = raw_data.select_dtypes(include='object').columns\n",
    "\n",
    "        \n",
    "        encoder = OrdinalEncoder()\n",
    "        raw_data[categorical_cols] = encoder.fit_transform(raw_data[categorical_cols])\n",
    "\n",
    "        X = raw_data.drop(labels = self.config.param_target_col, axis = 1)\n",
    "        y = raw_data[self.config.param_target_col]\n",
    "        \n",
    "        scaler = RobustScaler()\n",
    "        numerical_cols = X.select_dtypes(include='number').columns\n",
    "        X[numerical_cols] = scaler.fit_transform(X[numerical_cols])\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state= self.config.param_random_state)\n",
    "        X_train.reset_index(drop=True,inplace = True)\n",
    "        X_test.reset_index(drop=True,inplace = True)\n",
    "        y_train.reset_index(drop=True,inplace = True)\n",
    "        y_test.reset_index(drop=True,inplace = True)\n",
    "\n",
    "\n",
    "        train_data = pd.concat([X_train,y_train],axis = 1)\n",
    "        test_data = pd.concat([X_test,y_test],axis = 1)\n",
    "\n",
    "\n",
    "        pca = PCA(n_components=5)\n",
    "        X_train_pca = pca.fit_transform(X_train) \n",
    "        X_test_pca = pca.transform(X_test) \n",
    "        X_train_pca = pd.DataFrame(X_train_pca)\n",
    "        X_test_pca = pd.DataFrame(X_test_pca)\n",
    "\n",
    "\n",
    "        train_pca_data = pd.concat([X_train_pca,y_train],axis = 1)\n",
    "        test_pca_data = pd.concat([X_test_pca,y_test],axis = 1)\n",
    "        \n",
    "\n",
    "        training_path = self.config.save_training_file \n",
    "        save_data(Path(training_path),train_data,\"train.csv\")\n",
    "        save_data(Path(training_path),test_data,\"test.csv\")\n",
    "        save_data(Path(training_path),train_pca_data,\"train_pca.csv\")\n",
    "        save_data(Path(training_path),test_pca_data,\"test_pca.csv\")\n",
    "        \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-17 23:10:59,588: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-06-17 23:10:59,590: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-06-17 23:10:59,591: INFO: common: The directory artifacts already exists]\n",
      "[2024-06-17 23:10:59,591: INFO: common: The directory artifacts/data_ingestion already exists]\n",
      "[2024-06-17 23:10:59,592: INFO: common: The directory artifacts/training already exists]\n",
      "[2024-06-17 23:10:59,592: INFO: 3312381835: File already downloaded]\n",
      "[2024-06-17 23:10:59,634: INFO: 3312381835: length X=8124]\n",
      "[2024-06-17 23:10:59,645: INFO: 3312381835: length X=8124]\n",
      "[2024-06-17 23:10:59,648: INFO: 3312381835: length X=6499]\n",
      "[2024-06-17 23:10:59,650: INFO: 3312381835: length train_data=6499]\n",
      "[2024-06-17 23:10:59,654: INFO: 3312381835: length train_pca=6499]\n",
      "[2024-06-17 23:10:59,655: INFO: 3312381835: length X_train_pca=6499]\n",
      "[2024-06-17 23:10:59,656: INFO: 3312381835: length y_train=6499]\n",
      "[2024-06-17 23:10:59,656: INFO: 3312381835: length train_pca=6499]\n",
      "[2024-06-17 23:10:59,712: INFO: common: File train.csv saved]\n",
      "[2024-06-17 23:10:59,727: INFO: common: File test.csv saved]\n",
      "[2024-06-17 23:10:59,763: INFO: common: File train_pca.csv saved]\n",
      "[2024-06-17 23:10:59,772: INFO: common: File test_pca.csv saved]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_ingestion_manipulation_config = config.get_data_ingestion_config()\n",
    "    data_ingestion_manipulation = DataIngestionManipulation(config=data_ingestion_manipulation_config)\n",
    "    data_ingestion_manipulation.download_file()\n",
    "    \n",
    "    data_ingestion_manipulation.preprocess_file()\n",
    "    \n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
